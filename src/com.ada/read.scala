package com.ada

import org.apache.spark.{SparkContext, SparkConf}

/**
 * Created by HM on 2015/9/16.
 */
object read {
  def main(args: Array[String]) {


//    val conf = new SparkConf().setAppName("readFile")
//    val sc = new SparkContext(conf)
//
//    val rdd = sc.textFile("hdfs://node1:9000/user/humeng/fileShen/shen.csv")
//    val list = rdd.toArray()
//    for(l <- list){
//      println(l.split(",")(1))
//    }


  }
}
